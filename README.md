TANAP Segmentation 

This program takes in directories containing page scan XML data from the National Archives, generated by LOGHI and outputs “inferred” document boundaries with respect to the inventory. Each scan page can be classified as either (“START” - The starting page of a document, “END” - The ending page of a document, “MIDDLE” - A middle page in-between a start and end page, “NONE” - A page outside of a document, such as table of contents, or blank pages). The output given by the program is a two-column csv file contains the scan file name and its denoted page boundary.

 How to Run (Script Version):
1. Make sure you have the latest version of python and conda installed
2. Install and activate the environment via the yml file in the repository
3. Make sure you have a folder/directory containing only xml files from a specific inventory
4. Navigate to the “Script Version of Segmentation Classifier” folder in terminal
5. Type in terminal "python apply_model.py <XML_DIR> <MODEL_PATH> <LABEL_ENCODER_PATH> <OUTPUT_CSV>"
6. The items in <brackets> should be replaced with the paths to your directories. For the <MODEL_PATH> and <LABEL_ENCODER_PATH> sections, you can find the files in the same directory as apply_model.py*.
7. Run the command
8. Enjoy

* For this version select “label_encoder53.joblib” and “xgb_53_best_model.joblib”
